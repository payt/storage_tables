# frozen_string_literal: true

module StorageTables
  # Representation of a file with the location of the file stored in a database table.
  class Blob < ApplicationRecord
    include StorageTables::Blobs::Identifiable

    self.primary_key = [:checksum, :partition_key]

    store :metadata, accessors: [:analyzed, :identified, :mtime], coder: ActiveRecord::Coders::JSON

    class_attribute :services, default: {}
    class_attribute :service, instance_accessor: false
    class_attribute :service_name

    validates :checksum, presence: true

    after_initialize do
      self.service_name ||= self.class.service.name
    end

    def checksum=(value)
      self[:partition_key] = value[0]
      self[:checksum] = value[1..].chomp("==")
    end

    def checksum
      return unless self[:checksum]

      "#{partition_key}#{self[:checksum]}=="
    end

    def destroy!
      raise StorageTables::ActiveRecordError, "Cannot delete blob attached to a record" if attachments_count.positive?

      delete_result = service.delete(checksum)

      begin
        super
      rescue StandardError
        service.restore(checksum, delete_result)

        raise
      end
    end

    # Check if file exists on disk
    def on_disk?
      service.exist?(checksum)
    end

    class << self
      def build_after_unfurling(io:, content_type: nil, metadata: nil)
        checksum = compute_checksum_in_chunks(io)
        existing_blob = find_by_checksum(checksum)

        return existing_blob if existing_blob

        new_blob = new(content_type:, metadata:, checksum:)
        new_blob.unfurl(io)
        new_blob
      end

      def create_after_unfurling!(...)
        build_after_unfurling(...).tap(&:save!)
      end

      # Creates a new blob instance and then uploads the contents of
      # the given <tt>io</tt> to the service. The blob instance is going to
      # be saved before the upload begins to prevent the upload clobbering another due to key collisions.
      def create_and_upload!(io:, content_type: nil, metadata: nil)
        create_after_unfurling!(io:, content_type:, metadata:).tap do |blob|
          blob.upload_without_unfurling(io)
        end
      end

      # Returns a saved blob _without_ uploading a file to the service. This blob will point to a key where there is
      # no file yet. It's intended to be used together with a client-side upload, which will first create the blob
      # in order to produce the signed URL for uploading. This signed URL points to the key generated by the blob.
      # Once the form using the direct upload is submitted, the blob can be associated with the right record using
      # the signed ID.
      def create_before_direct_upload!(byte_size:, checksum:, content_type:, metadata: nil)
        create!(byte_size:, checksum:, content_type:, metadata:)
      end

      def existing_blob(checksum)
        StorageTables.deprecator.warn(
          "[StorageTables] #existing_blob is deprecated. " \
          "Use #find_by_checksum instead."
        )
        find_by_checksum(checksum)
      end

      def find_by_checksum(checksum)
        find_by(partition_key: checksum[0], checksum: checksum[1..].chomp("=="))
      end

      def find_by_checksum!(checksum)
        find_by!(partition_key: checksum[0], checksum: checksum[1..].chomp("=="))
      end

      def where_checksum(input)
        if input.is_a?(Array)
          where(primary_key => input.map { checksum_to_primary(_1) })
        else
          where(partition_key: input[0], checksum: input[1..].chomp("=="))
        end
      end

      def compute_checksum_in_chunks(io)
        OpenSSL::Digest.new("SHA3-512").tap do |checksum|
          while (chunk = io.read(5.megabytes))
            checksum << chunk
          end

          io.rewind
        end.base64digest
      end

      private

      # Cut the checksum into an Array to match the primary key
      def checksum_to_primary(checksum)
        [checksum[1..].chomp("=="), checksum[0]]
      end
    end

    def unfurl(io)
      self.content_type = extract_content_type(io)
      self.byte_size = io.size
      self.identified = true
    end

    # Uploads the file associated with this blob to the service.
    # When uploading fails the blob is deleted from the database, as it is not usable.
    def upload_without_unfurling(io)
      service.upload checksum, io, checksum:, **service_metadata
    rescue StorageTables::ServiceError
      destroy!
      raise
    end

    # Downloads the file associated with this blob. If no block is given,
    # the entire file is read into memory and returned.
    # That'll use a lot of RAM for very large files. If a block is given,
    # then the download is streamed and yielded in chunks.
    def download(&)
      service.download(checksum, &)
    end

    # Returns a URL that can be used to directly upload a file for this blob on the service. This URL is intended to be
    # short-lived for security and only generated on-demand by the client-side JavaScript responsible for doing the
    # uploading.
    def service_url_for_direct_upload(expires_in: 15.minutes)
      service.url_for_direct_upload checksum, expires_in:, content_type:, content_length: byte_size
    end

    # Returns an instance of service, which can be configured globally or per attachment
    def service
      services.fetch(service_name)
    end

    private

    def extract_content_type(io)
      Marcel::MimeType.for io, declared_type: content_type
    end

    def forcibly_serve_as_binary?
      ActiveStorage.content_types_to_serve_as_binary.include?(content_type)
    end

    def allowed_inline?
      ActiveStorage.content_types_allowed_inline.include?(content_type)
    end

    def service_metadata
      if forcibly_serve_as_binary?
        { content_type: ActiveStorage.binary_content_type, disposition: :attachment }
      elsif !allowed_inline?
        { content_type:, disposition: :attachment }
      else
        { content_type: }
      end
    end
  end
end

ActiveSupport.run_load_hooks :storage_tables_blob, StorageTables::Blob
